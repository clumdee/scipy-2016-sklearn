{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Andreas Mueller, Kyle Kastner, Sebastian Raschka' -v -p numpy,scipy,matplotlib,scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy 2016 Scikit-learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.538380\n",
      "n_neighbors: 3, average score: 0.740929\n",
      "n_neighbors: 5, average score: 0.757285\n",
      "n_neighbors: 10, average score: 0.711777\n",
      "n_neighbors: 20, average score: 0.608429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "# create 2D matrix X with shape = (n_samples, n_features) from 1D matrix X\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b742af6828>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSLpUJIiIiEi6VCSIiIhIuv4f9mtFSI74ih0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b742a9bba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "\n",
    "# return 2D error matrix with shape = (n_param_scan, n_cv_scan)\n",
    "train_errors, test_errors = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "\n",
    "# plot mean error for each param_scan (average over n_cv_scan)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label=\"train error\")\n",
    "plt.plot(n_neighbors, test_errors.mean(axis=1), label=\"test error\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot is the mirror image of the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.042946\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.008101\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.027729\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.076927\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.037444\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.002649\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.087607\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.085148\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.014532\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.149221\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.524063\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.406942\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.161081\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.571559\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.676671\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.696725\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.590316\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.552329\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.650185\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.695263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.087665, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.028236, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.831720, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.029885, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.109854, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.021072, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.242078, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.003608, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.011553, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.006799, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.084715, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.025552, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.824926, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.027076, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.106083, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.018139, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.236794, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.001369, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.008104, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.004231, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.072196, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.013562, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.797756, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.014739, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.089360, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.005278, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.212833, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.009316, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.006258, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.007990, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.074515, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.015110, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.805022, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.016829, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.091726, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.007266, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.215022, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.008928, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.003571, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.007581, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.084403, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.025287, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.824144, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.026796, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.105705, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.017844, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.236281, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.001178, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.007743, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.003996, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.055765, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.001102, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.745839, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.000410, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.069438, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.012767, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.185076, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.020604, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.025529, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.021221, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.031833, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.102126, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.505743, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.104278, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.073532, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.118902, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.036007, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.119443, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.141711, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.127427, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.001407, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.091716, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.527231, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.082232, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.068766, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.099701, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.075303, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.119076, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.129361, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.130060, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.053615, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.003662, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.734966, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.003124, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.064787, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.016066, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.180578, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.022465, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.028992, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.023503, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.114813, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.198268, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-0.231836, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.202668, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.165808, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.224292, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.103289, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.201136, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.276876, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.221979, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.397275, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.523034, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.500160, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.514496, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.587636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.497824, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.451330, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.555900, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.616131, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.598506, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.375481, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.518325, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.367549, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.501195, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.606525, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.517150, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.431371, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.563289, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.604292, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.603212, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.124779, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.209780, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................ C=1, gamma=0.001, score=-0.197025, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.221174, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.179866, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.243472, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.128668, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.212865, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.300122, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.238120, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.453441, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.621507, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.662441, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.596413, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.634017, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.512062, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.497115, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.604073, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.612566, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.626111, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.438477, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.756834, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.772572, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.612063, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.712122, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.520306, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.492903, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.764606, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.620909, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.763311, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.519405, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.821355, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.666413, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.706677, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.733127, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.638210, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.520893, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.804780, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.679398, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.767433, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.462426, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.614740, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.658579, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.586545, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.633709, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.505651, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.488184, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.587676, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.602154, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.609605, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.457643, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.679359, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.659928, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.612965, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.685140, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.441580, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.462163, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.659875, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.523486, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.661930, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.427000, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.779033, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.755990, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.594428, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.711422, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.505172, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.481550, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.793828, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.611228, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.772295, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.622134, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.864087, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.398848, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.829751, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.644026, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.721567, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.566701, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.844016, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.708618, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.822396, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702214304117\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=1,\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.114816, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.114657, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.112392, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.110405, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.114696, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.110850, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.068111, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.059550, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.110321, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-0.041193, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.271436, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.256273, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................ C=1, gamma=0.001, score=-0.030869, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.247682, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.397118, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.441862, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.230245, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.257421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.402978, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.468798, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If cv=None, 3-fold is used by default \n",
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.975771, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.986607, total=   0.1s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_neighbors=1, score=0.979775, total=   0.1s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .................... n_neighbors=4, score=0.975771, total=   0.1s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .................... n_neighbors=4, score=0.984375, total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .................... n_neighbors=4, score=0.964045, total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .................... n_neighbors=9, score=0.977974, total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .................... n_neighbors=9, score=0.982143, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .................... n_neighbors=9, score=0.950562, total=   0.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................... n_neighbors=16, score=0.966960, total=   0.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................... n_neighbors=16, score=0.975446, total=   0.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................... n_neighbors=16, score=0.952809, total=   0.1s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ................... n_neighbors=25, score=0.969163, total=   0.1s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ................... n_neighbors=25, score=0.970982, total=   0.1s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ................... n_neighbors=25, score=0.937079, total=   0.1s\n",
      "Best grid parameter: {'n_neighbors': 1}\n",
      "Best train score: 0.980698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.993333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)\n",
    "\n",
    "n_neighbors = np.array([x**2 for x in range(1,6)])\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':n_neighbors}\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid=param_grid, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best grid parameter: %s' % grid.best_params_)\n",
    "print('Best train score: %f' % grid.best_score_)\n",
    "\n",
    "print('Score on test set: %f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.970803, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988764, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988636, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.981752, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985240, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985019, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985401, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.996310, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.974170, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985019, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.978102, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981550, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.977860, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981273, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.927007, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.929889, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.952030, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.921348, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.958333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
